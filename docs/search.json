[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "YT Notes",
    "section": "",
    "text": "Datatable notes\n\n\n\n\n\n\n\nr\n\n\n\n\nCommand reference for the datatable package\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGit commands\n\n\n\n\n\n\n\nterminal\n\n\n\n\nCommonly used git commands\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nLinux Commands\n\n\n\n\n\n\n\nterminal\n\n\nlinux\n\n\n\n\nUseful Linux terminal commands\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nMiniconda3 commands\n\n\n\n\n\n\n\nterminal\n\n\n\n\nTypical terminal commands for Miniconda 3\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nModelling\n\n\n\n\n\n\n\nr\n\n\n\n\nCode recipes for modelling in R\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPolars notes\n\n\n\n\n\n\n\nr\n\n\npython\n\n\n\n\nCommand reference for the polars Python package, with R equivalents\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nQuarto Cheatsheet\n\n\n\n\n\n\n\nquarto\n\n\n\n\nBasic Quarto syntax\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nR install notes\n\n\n\n\n\n\n\nr\n\n\nterminal\n\n\nwindows\n\n\nmac\n\n\nlinux\n\n\n\n\nNotes on how to install R and RStudio, specific to each platform.\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSQL Commands\n\n\n\n\n\n\n\nsql\n\n\n\n\nA listing of some useful SQL commands\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWSL2 Notes\n\n\n\n\n\n\n\nterminal\n\n\nwindows\n\n\nlinux\n\n\n\n\nUseful WSL2 commands\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nWebscraping in R\n\n\n\n\n\n\n\nr\n\n\n\n\nHow to perform webscraping in R, using the rvest package\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "other/slides/index.html#quarto",
    "href": "other/slides/index.html#quarto",
    "title": "Ying’s Slides",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished presentation. To learn more about Quarto presentations see https://quarto.org/docs/presentations/."
  },
  {
    "objectID": "other/slides/index.html#bullets",
    "href": "other/slides/index.html#bullets",
    "title": "Ying’s Slides",
    "section": "Bullets",
    "text": "Bullets\nWhen you click the Render button a document will be generated that includes:\n\nContent authored with markdown\nOutput from executable code"
  },
  {
    "objectID": "other/slides/index.html#code",
    "href": "other/slides/index.html#code",
    "title": "Ying’s Slides",
    "section": "Code",
    "text": "Code\nWhen you click the Render button a presentation will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n\n[1] 2"
  },
  {
    "objectID": "other/slides/index.html#code-chunk",
    "href": "other/slides/index.html#code-chunk",
    "title": "Ying’s Slides",
    "section": "Code chunk",
    "text": "Code chunk\nHere is a code chunk:\n\nggplot(diamonds,aes(x=carat,y=price,color=cut)) + geom_point()"
  },
  {
    "objectID": "other/slides/index.html#table",
    "href": "other/slides/index.html#table",
    "title": "Ying’s Slides",
    "section": "Table",
    "text": "Table\nHere is a table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\nMerc 450SE\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\nMerc 450SL\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\nMerc 450SLC\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\nCadillac Fleetwood\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\nLincoln Continental\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\nChrysler Imperial\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\nFiat 128\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\nHonda Civic\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\nToyota Corolla\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\nToyota Corona\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2"
  },
  {
    "objectID": "other/slides/index.html#data-table",
    "href": "other/slides/index.html#data-table",
    "title": "Ying’s Slides",
    "section": "Data Table",
    "text": "Data Table\nHere is a table:"
  },
  {
    "objectID": "other/slides/index.html#citations-and-footnotes",
    "href": "other/slides/index.html#citations-and-footnotes",
    "title": "Ying’s Slides",
    "section": "Citations and Footnotes",
    "text": "Citations and Footnotes\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this. The echo: false option disables the printing of code (only output is displayed).\nHere is a footnote reference,1 and another.2 You can also reference inline!3\n\nThe whole paragraph can be indented, or just the first line. In this way, multi-paragraph footnotes work like multi-paragraph list items.\nHere is a sentence with citation using bibliography.1\nThe sentence has multiple references.2–4\n\n\n\n\n\n\n1. Cordonnier, C. et al. Randomized study of early versus late immunization with pneumococcal conjugate vaccine after allogeneic stem cell transplantation. Clinical Infectious Diseases 48, 1392–1401 (2009).\n\n\n2. Adibi, M. et al. Reduction in hospital admission rates due to post-prostate biopsy infections after augmenting standard antibiotic prophylaxis. The Journal of urology (2012).\n\n\n3. Gold, M. C. et al. Human innate mycobacterium tuberculosis–reactive \\(\\alpha\\)\\(\\beta\\)TCR+ thymocytes. PLoS pathogens 4, e39 (2008).\n\n\n4. Roach, M. B., George, W. J., Figueroa, T. E., Neal, D. E. & McBride, D. Ciprofloxacin versus gentamicin in prophylaxis against bacteremia in transrectal prostate needle biopsy. Urology 38, 84–87 (1991).\n\n\nHere is the footnote.Here’s one with multiple blocks. Subsequent paragraphs are indented to show that they belong to the previous footnote.\n{ some.code }\nHello. I am an inline footnote."
  },
  {
    "objectID": "posts/datatable/index.html",
    "href": "posts/datatable/index.html",
    "title": "Datatable notes",
    "section": "",
    "text": "Load package and data\n\n\n\nlibrary(tidyverse)\ndiamonds\nband_members\nband_instruments\n\n\n\n\n\nlibrary(data.table)\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\nband_members.dt &lt;- band_members %&gt;% as.data.table()\nband_instruments.dt &lt;- band_instruments %&gt;% as.data.table()\n\n\n\n\nGenerate a data frame from scratch\n\n\n\ntibble(\n  id=1:3,\n  color=c(\"blue\",\"red\",\"green\"),\n  size=c(\"small\",\"medium\",\"large\")\n)\n\n\n\n\n\ndata.table(\n  id=1:3,\n  color=c(\"blue\",\"red\",\"green\"),\n  size=c(\"small\",\"medium\",\"large\")\n)\n\n\n\n\n\nRead in a TSV file, explicitly\n\n\n\nfile &lt;- \"C:/Users/Ying/Desktop/samples/mock/Sample_GutZymo1_IGO_13699_36.kaiju_summary1.tsv\"\ncols &lt;- list(\n  \"outfile\"=col_character(), \n  \"percent\"=col_double(),\n  \"numseqs\"=col_integer(),\n  \"taxid\"=col_character(), \n  \"taxon_name\"=col_skip()\n)\ntable &lt;- read_tsv(file,skip=1,col_names=names(cols),col_types=cols, na=c(\"\", \"NA\"))\n\n\n\n\n\nfile &lt;- \"C:/Users/Ying/Desktop/samples/mock/Sample_GutZymo1_IGO_13699_36.kaiju_summary1.tsv\"\ncols2 &lt;- c(\n  \"outfile\"=\"character\", \n  \"percent\"=\"numeric\",\n  \"numseqs\"=\"numeric\",\n  \"taxid\"=\"character\",\n  \"taxon_name\"=NA\n)\ndrop &lt;- which(is.na(cols)) %&gt;% unname()\ncol.names &lt;- names(cols)[!is.na(cols)]\ncolClasses &lt;- cols[!is.na(cols)] %&gt;% {setNames(seq_along(.),.)} %&gt;% as.list()\ntable2 &lt;- fread(file,header=TRUE,\n                drop=drop,col.names = col.names,\n                colClasses=colClasses,na.strings=c(\"\",\"NA\"))\n\n\n\n\n\n\nRow/Column Filtering\n\nExtract top 3 rows\n\n\n\ndiamonds[1:3,] #method 1\nhead(diamonds,3) #method 2\ndiamonds %&gt;% slice(1:3) #method 3\n\n\n\n\n\ndiamonds.dt[1:3,] #method 1\ndiamonds.dt[1:3] #method 2\n\n\n\n\n\nMultiple row filter criteria\n\n\n\ndiamonds %&gt;% \n  filter(clarity==\"VVS1\",\n         price&gt;2000,\n         grepl(\"[DEF]\",color))\n\n\n\n\n\ndiamonds.dt[clarity==\"VVS1\" & \n              price&gt;2000 & \n              grepl(\"[DEF]\",color)]\n\n\n\n\n\n\nSelect/Rename columns\n\nRoutine select\n\n\n\ndiamonds %&gt;% select(carat,cut,clarity)\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n#method 1\ndiamonds.dt[, c(\"carat\",\"cut\",\"clarity\")] \n#method 2\ndiamonds.dt[, list(carat,cut,clarity)] \n#method 3\ncols &lt;- c(\"carat\",\"cut\",\"clarity\") \ndiamonds.dt[, ..cols]\n#method 4\ndiamonds.dt[, .(carat,cut,clarity)] \n\n\n\n\n\nSelect columns using regex pattern\n\n\n\ndiamonds %&gt;% select(matches(\"^c\"))\n\n\n\n\n\n#method 1\ncols &lt;- grep(\"^c\",  names(diamonds.dt)) \ndiamonds.dt[, ..cols]\n#method 2\ndiamonds.dt[, .SD, .SDcols=patterns(\"^c\")] \n\n\n\n\n\nSelect columns of a certain type\n\n\n\ndiamonds %&gt;% select(where(is.factor))\n\n\n\n\n\ndiamonds.dt[, .SD, .SDcols = is.factor]\n\n\n\n\n\nSelect all columns except those specified\n\n\n\ndiamonds %&gt;% select(-c(x,y,z))\n\n\n\n\n\n#method 1\ndiamonds.dt[, !c(\"x\",\"y\",\"z\")]\n#method 2\ncols &lt;- c(\"x\",\"y\",\"z\") \ndiamonds.dt[, -..cols]\n\n\n\n\n\nSelect columns and rename\n\n\n\ndiamonds %&gt;% select(price_usd=price,length=x,width=y,depth=z)\n\n\n\n\n\n# by reference!\nsetnames(diamonds.dt,\n         old=c(\"price\",\"x\",\"y\",\"z\"),\n         new=c(\"price_usd\",\"length\",\"width\",\"depth\"))\n\n\n\n\n\nSelect all columns and add prefix\n\n\n\ndiamonds %&gt;% rename_with(.fn=~paste0(\"var_\",.))\n\n\n\n\n\n# by reference!\nsetnames(diamonds.dt,\n         old=names(diamonds.dt),\n         new=paste0(\"var_\",names(diamonds.dt)))\n\n\n\n\n\nSelect and programmatically rename\n\n\n\nvarmap &lt;- c(\"price_usd\"=\"price\",\n            \"length\"=\"x\",\n            \"width\"=\"y\",\n            \"depth\"=\"z\")\ndiamonds %&gt;% select(!!!varmap)\n\n\n\n\n\n# by reference!\nvarmap &lt;- c(\"price_usd\"=\"price\",\n            \"length\"=\"x\",\n            \"width\"=\"y\",\n            \"depth\"=\"z\")\nsetnames(diamonds.dt,old=varmap,new=names(varmap))\n\n\n\n\n\n\nMutate/Transmute\n\nMutate\n\n\n\ndiamonds %&gt;%\n  mutate(price_thousands=price*1000,\n         log_price=log(price),\n         xyz=paste(x,y,z,sep=\"+\"))\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n# by reference!\n#method 1\n(diamonds.dt[, price_thousands:=price*1000]\n            [, log_price:=log(price)]\n            [,xyz:=paste(x,y,z,sep=\"+\")])\n#method 2\ndiamonds.dt[, c(\"price_thousands\",\"log_price\",\"xyz\"):=.(price*1000,\n                                                        log(price),\n                                                        paste(x,y,z,sep=\"+\"))]\n#method 3\ndiamonds.dt[, ':='(price_thousands=price*1000,\n                   log_price=log(price),\n                   xyz=paste(x,y,z,sep=\"+\"))]\n\n\n\n\n\nTransmute\n\n\n\ndiamonds %&gt;%\n  transmute(\n    color_is_DEF=color %in% c(\"D\",\"E\",\"F\"),\n    clarity=str_to_title(clarity),\n    cut.rating=if_else(cut %in% c(\"Ideal\",\"Premium\"),\"great\",\"ok\"),\n    color_status=case_when(\n      color==\"J\" ~ \"very poor\",\n      color %in% c(\"H\",\"I\") ~ \"poor\",\n      color %in% c(\"F\",\"G\") ~ \"ok\",\n      TRUE ~ \"excellent\"\n    ))\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\ndiamonds.dt[,.(color_is_DEF=color %in% c(\"D\",\"E\",\"F\"),\n               clarity=str_to_title(clarity),\n               cut.rating=fifelse(cut %in% c(\"Ideal\",\"Premium\"),\"great\",\"ok\"),\n               color_status=fcase(\n                 color==\"J\", \"very poor\",\n                 color %in% c(\"H\",\"I\"), \"poor\",\n                 color %in% c(\"F\",\"G\"), \"ok\",\n                 default = \"excellent\"))]\n\n\n\n\n\n\nGroup By and Summarize\n\nCount rows by group\n\n\n\ndiamonds %&gt;% \n  group_by(cut,color) %&gt;%\n  summarize(n=n(),\n            .groups=\"drop\")\n\ndiamonds %&gt;% count(cut,color) #shortcut\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\ndiamonds.dt[, .(n=.N), by = c(\"cut\",\"color\")]\n\n\n\n\n\nCalculate various summaries by group\n\n\n\ndiamonds %&gt;%\n  group_by(cut) %&gt;%\n  summarize(n=n(),\n            mean_price=mean(price),\n            max_price=max(price),\n            available_colors=paste(sort(unique(color)),collapse=\", \"),\n            .groups=\"drop\")\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\ndiamonds.dt[, by=cut,\n            .(n=.N,\n              mean_price=mean(price),\n              max_price=max(price),\n              available_colors=paste(sort(unique(color)),collapse=\", \"))] \n\n\n\n\n\nSelect first row after sorting, by group\n\n\n\ndiamonds %&gt;%\n  group_by(cut) %&gt;%\n  arrange(desc(price),depth) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\n\n(diamonds.dt[,.SD[order(-price,depth)], by=cut]\n  [,.SD[1], by=cut])\n\ndiamonds.dt[,.SD[order(-price,depth)][1], by=cut]\n\n\n\n\n\n\nApply function across columns\n\nApply to all columns\n\n\n\ndiamonds %&gt;% \n  mutate(across(.fns=~paste0(.,\"_xyz\")))\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\ndiamonds.dt[,lapply(.SD, function(x) paste0(x,\"_xyz\"))]\n\n\n\n\n\nApply to columns using regex\n\n\n\ndiamonds %&gt;%\n  transmute(across(.cols=matches(\"^c\"),.fns=~paste0(.,\"_x\")))\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\ndiamonds.dt[,lapply(.SD,function(x) paste0(x,\"_x\")),\n            .SDcols=patterns(\"^c\")]\n\n\n\n\n\nApply to columns of a certain type\n\n\n\ndiamonds %&gt;%\n  mutate(across(.cols=where(is.numeric),\n                .fns=~. * 1000))\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\n\ndiamonds.dt[,lapply(.SD,function(x) {\n  if (is.numeric(x)) x*1000 else x\n})]\n\n\n\n\n\n\nJoins\n\nLeft join\n\n\n\nband_members %&gt;% left_join(band_instruments,by=\"name\")\n\n\n\n\n\nband_instruments.dt[band_members.dt, on = \"name\"]\n\nmerge(band_members.dt, \n      band_instruments.dt, \n      all.x = TRUE, by = \"name\")\n\n\n\n\n\nInner join\n\n\n\nband_members %&gt;% inner_join(band_instruments,by=\"name\")\n\n\n\n\n\nband_members.dt[band_instruments.dt, on=\"name\",nomatch=0]\n\nmerge(band_members.dt, band_instruments.dt, by=\"name\")\n\n\n\n\n\nOuter join\n\n\n\nband_members %&gt;% full_join(band_instruments,by=\"name\")\n\n\n\n\n\nmerge(band_members.dt, band_instruments.dt, all = TRUE, by = \"name\")\n\n\n\n\n\nAnti join\n\n\n\nband_members %&gt;% anti_join(band_instruments,by=\"name\")\n\n\n\n\n\nband_members.dt[!band_instruments.dt, on =\"name\"]\n\n\n\n\n\n\nPivoting/Reshaping\n\nPivot Longer\n\n\n\ndiamonds %&gt;%\n  pivot_longer(cols=c(x,y,z),names_to=\"axis\",values_to=\"mm\")\n\n\n\n\n\nmelt(diamonds.dt,\n     measure.vars = c(\"x\",\"y\",\"z\"),\n     variable.name=\"axis\",\n     value.name=\"mm\")\n\n\n\n\n\nPivot Wider\n\n\n\ndiamonds %&gt;%\n  pivot_wider(id_cols=clarity,names_from=cut,values_from=price,values_fn=mean)\n\n\n\n\n\ndcast(diamonds.dt,\n      clarity ~ cut, \n      value.var=\"price\",fun.aggregate = mean)\n\n\n\n\n\n\nNested columns\n\nSplit string column into nested list, unnest into long format\n\n\n\ndiamonds %&gt;%\n  mutate(cut_word=str_split(cut,\" \")) %&gt;%\n  unnest(cut_word)\n\n\n\n\n\n# diamonds.dt &lt;- diamonds %&gt;% as.data.table()\n# diamonds.dt[, cut_word:=str_split(cut,\" \")]\n# ????????????????????????\n# diamonds.dt[, .(cut_word=cut_word[[1]]), by=c(...)]\n\n\n\n\n\nGroup by a variable and tally others in a nested field\n\n\n\ndiamonds %&gt;%\n  group_by(cut) %&gt;%\n  summarize(clarity_table=list(table(clarity)),\n            .groups=\"drop\")\n\n\n\n\n\n# ????????????????????????\n\n\n\n\n\nMove columns into single nested column, then unnest to individual columns again.\n\n\n\ndiamonds %&gt;%\n  nest(col_color_clarity=c(cut,color,clarity)) %&gt;%\n  unnest(col_color_clarity)\n\n\n\n\n\n# ????????????????????????\n\n\n\n\n\nNested table in a single column, by group\n\n\n\ndiamonds %&gt;%\n  group_by(color) %&gt;%\n  nest(group_info=-color) %&gt;%\n  ungroup()\n\n\n\n\n\n# ????????????????????????\n\n\n\n\n\n\nProgrammatic statements\n\nInject list of expressions into a group_by/summarize\n\n\n\nbyvar &lt;- c(\"cut\",\"color\",\"clarity\")\ncmds &lt;- rlang::exprs(\n  mean.depth = mean(depth),\n  min.price = min(price),\n  max.price = max(price),\n  n=n()\n)\n\ndiamonds %&gt;%\n  group_by(!!!syms(byvar)) %&gt;%\n  summarize(!!!cmds,\n            .groups=\"drop\")\n\n\n\n\n\ndiamonds.dt &lt;- diamonds %&gt;% as.data.table()\nbyvar &lt;- c(\"cut\",\"color\",\"clarity\")\ncmds &lt;- rlang::exprs(\n  mean.depth = mean(depth),\n  min.price = min(price),\n  max.price = max(price),\n  n=.N\n)\n\nrlang::inject(diamonds.dt[, .(!!!cmds), by=byvar])"
  },
  {
    "objectID": "posts/git_commands/index.html",
    "href": "posts/git_commands/index.html",
    "title": "Git commands",
    "section": "",
    "text": "Download repository\ngit clone https://github.com/ying14/yingtools2\nInspect origins\ngit remote -v\nShows what branch we are on, and which files have changed, whether staged or not.\ngit status\nStage changes\ngit add README.md\nUndo staging\ngit reset HEAD README.md\nStage changes\ngit add --all\ngit add README.md for a specific file\nCommit staged changes\ngit commit -m 'message'\nPush committed changes\ngit push\nPull committed changes\ngit pull\nLog of changes, with hash\ngit log\nfresh install of repo\ngit fetch --all\ngit reset --hard origin/main\ngit pull origin main"
  },
  {
    "objectID": "posts/linux_commands/index.html",
    "href": "posts/linux_commands/index.html",
    "title": "Linux Commands",
    "section": "",
    "text": "find . -iname '*.pdf*'\n\n\nUse -iname for case-insensitive, -name for case sensitive\n\n\n\nfind . -iregex '.*800.*oligos'\n\n\nNote that this matches the entire filepath. Use -iregex for case-insensitive, -regex for case sensitive.\nAlternatively, do a pipe to grep to do partial matching:\nfind . | grep -i '800.*oligos*'\n\n\n-i makes it case insensitive\n\n\n\nfind .  -name '*.txt*' -print0 | xargs -0 grep 'something'\n\nfind . -name '*.txt*' -exec grep -i 'something' {} \\; \n# case insensitive\n\n\n\ngrep -C 2 'keyword' file.txt\n\n\n\nfind . -name “*.f” -exec grep -nHo the_string {} ;\nfind . -name '*json*' -printf \"%-25p %t\\n\"\n\n\n\nfind -type f \\( -name 'reads?.fastq' -o -name 'barcodes.fastq' \\)\n\n\n\nfind -type f -iname '*.fastq.gz' -exec du {} + | awk '{ total += $1 }; END { print total/1023/1023,\"Gb\" }' \n\n\n\nfind -type f -iname '*.fastq.gz' -delete\n\n\n\nfind . -name '*.txt' | cpio -pdm /path\n\n# this also works but is a little wonky\nfind . -name '*.mp3' -exec cp {} /path \\;\n\n\n\nfind .-type d -maxdepth 1\n\n\n\nmount -l\nlsblk"
  },
  {
    "objectID": "posts/linux_commands/index.html#find-files",
    "href": "posts/linux_commands/index.html#find-files",
    "title": "Linux Commands",
    "section": "",
    "text": "find . -iname '*.pdf*'\n\n\nUse -iname for case-insensitive, -name for case sensitive\n\n\n\nfind . -iregex '.*800.*oligos'\n\n\nNote that this matches the entire filepath. Use -iregex for case-insensitive, -regex for case sensitive.\nAlternatively, do a pipe to grep to do partial matching:\nfind . | grep -i '800.*oligos*'\n\n\n-i makes it case insensitive\n\n\n\nfind .  -name '*.txt*' -print0 | xargs -0 grep 'something'\n\nfind . -name '*.txt*' -exec grep -i 'something' {} \\; \n# case insensitive\n\n\n\ngrep -C 2 'keyword' file.txt\n\n\n\nfind . -name “*.f” -exec grep -nHo the_string {} ;\nfind . -name '*json*' -printf \"%-25p %t\\n\"\n\n\n\nfind -type f \\( -name 'reads?.fastq' -o -name 'barcodes.fastq' \\)\n\n\n\nfind -type f -iname '*.fastq.gz' -exec du {} + | awk '{ total += $1 }; END { print total/1023/1023,\"Gb\" }' \n\n\n\nfind -type f -iname '*.fastq.gz' -delete\n\n\n\nfind . -name '*.txt' | cpio -pdm /path\n\n# this also works but is a little wonky\nfind . -name '*.mp3' -exec cp {} /path \\;\n\n\n\nfind .-type d -maxdepth 1\n\n\n\nmount -l\nlsblk"
  },
  {
    "objectID": "posts/linux_commands/index.html#disk-usage",
    "href": "posts/linux_commands/index.html#disk-usage",
    "title": "Linux Commands",
    "section": "Disk usage",
    "text": "Disk usage\n\nFind largest file in directory (-a lists file sizes)\ndu -a /dir/ | sort -n -r | head -n 20\nsudo du -hx | sort -hr | head -n 20\n# du -h\n# du -k -d1 * | sort -nr | cut -f2 | xargs -d '\\n' du -sh\nRemove tmp files to make space on root\nsudo find /tmp -type f -atime +10 -delete\n\nsudo find /tmp -type f -atime +10 -exec du {} + | awk '{ total += $1 }; END { print total/1023/1023,\"Gb\" }' \n\n# du -h\n# du -k -d1 * | sort -nr | cut -f2 | xargs -d '\\n' du -sh"
  },
  {
    "objectID": "posts/linux_commands/index.html#x2go-commands",
    "href": "posts/linux_commands/index.html#x2go-commands",
    "title": "Linux Commands",
    "section": "X2GO commands",
    "text": "X2GO commands\nList sessions\nx2golistsessions\nying@iski0021[ying] 47409|ying-50-1666546387_stDKDE_dp32|50|iski0021|R|2022-10-23T13:33:07|eccbae477812d21a69840bf3a59515a1|10.252.13.86|39201|39202|2022-10-31T10:30:30|ying|680416|39203|-1|-1\nField 1 47409 is agent ID Field 2 ying-50-1666546387_stDKDE_dp32 is session ID.\nTerminate session\nx2goterminate-session &lt;sessio_ID&gt;"
  },
  {
    "objectID": "posts/miniconda/index.html",
    "href": "posts/miniconda/index.html",
    "title": "Miniconda3 commands",
    "section": "",
    "text": "Create conda environment\nconda create --name snowflakes biopython\nconda create --name snakes python=3.9\nList all conda environments\nconda env list\nconda info --envs\nActivate conda enviroment\nconda activate snowflakes\nDeactivate conda enviroment\nconda deactivate\nDelete conda environment\nconda remove --name ENV_NAME --all\nInstall mamba\nconda install -n base -c conda-forge mamba\nCreate R environment, from conda-forge, bioconda, and R channels.\nmamba create -n viz -c conda-forge -c bioconda -c R r-base r-tidyverse\nBecuase of R_LIBS_USER, the .libPaths()' needs to be set: EditR_HOME`/etc/Renviron.site\nR_LIBS_USER=C:/Users/Ying/AppData/Local/r-miniconda/envs/viz/lib/R/library\nRETICULATE_PYTHON specifies which python to use."
  },
  {
    "objectID": "posts/modelling/index.html",
    "href": "posts/modelling/index.html",
    "title": "Modelling",
    "section": "",
    "text": "library(yingtools2)\nlibrary(broom)\nlibrary(modelr)\nlibrary(tidyverse)\nmt &lt;- mtcars %&gt;% mutate(cyl=factor(cyl))"
  },
  {
    "objectID": "posts/modelling/index.html#linear-regression",
    "href": "posts/modelling/index.html#linear-regression",
    "title": "Modelling",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nLinear Regression (single var)\n\nmodel &lt;- lm(mpg ~ hp,data=mt)\nmt$yhat &lt;- predict(model)\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  30.1       1.63       18.4  6.64e-18\n2 hp           -0.0682    0.0101     -6.74 1.79e- 7\n\nggplot(mt) +\n  geom_point(aes(x=hp,y=mpg)) +\n  geom_line(aes(x=hp,y=yhat),color=\"red\")\n\n\n\n\n\n\nLinear Regression, show confidence and prediction (single var)\n\nmodel &lt;- lm(mpg ~ hp,data=mt)\nci &lt;- predict(model,interval=\"confidence\") %&gt;% cbind(mt)\npi &lt;- predict(model,interval=\"prediction\") %&gt;% cbind(mt)\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  30.1       1.63       18.4  6.64e-18\n2 hp           -0.0682    0.0101     -6.74 1.79e- 7\n\nggplot(mt) +\n  geom_point(aes(x=hp,y=mpg)) +\n  geom_line(data=pi,aes(x=hp,y=fit,color=\"predicted\")) + \n  geom_ribbon(data=pi,aes(x=hp,ymin=lwr,ymax=upr,fill=\"predicted\"),alpha=0.35,show.legend=FALSE) +\n  geom_line(data=ci,aes(x=hp,y=fit,color=\"confidence\")) + \n  geom_ribbon(data=ci,aes(x=hp,ymin=lwr,ymax=upr,fill=\"confidence\"),alpha=0.35,show.legend=FALSE)\n\n\n\n\n\n\nLinear Regression (multiple vars)\n\nmodel &lt;- lm(mpg ~ hp + cyl, data=mt)\ntidy(model)\n\n# A tibble: 4 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  28.7       1.59       18.0  5.92e-17\n2 hp           -0.0240    0.0154     -1.56 1.30e- 1\n3 cyl6         -5.97      1.64       -3.64 1.09e- 3\n4 cyl8         -8.52      2.33       -3.66 1.03e- 3\n\npdata &lt;- tibble(hp=seq_range(mt$hp,n=200)) %&gt;%\n  expand_grid(cyl=mt$cyl)\npdata$yhat &lt;- predict(model,newdata=pdata)\nggplot() +\n  geom_point(data=mt, aes(x=hp,y=mpg,color=cyl)) +\n  geom_line(data=pdata, aes(x=hp,y=yhat,color=cyl))\n\n\n\n\n\n\nLinear Regression (multiple vars, with interaction)\n\nmodel &lt;- lm(mpg ~ hp + cyl + hp*cyl, data=mt)\ntidy(model)\n\n# A tibble: 6 × 5\n  term        estimate std.error statistic       p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)  36.0       3.89        9.25 0.00000000104\n2 hp           -0.113     0.0457     -2.47 0.0206       \n3 cyl6        -15.3       7.43       -2.06 0.0496       \n4 cyl8        -17.9       5.26       -3.40 0.00216      \n5 hp:cyl6       0.105     0.0685      1.54 0.137        \n6 hp:cyl8       0.0985    0.0486      2.03 0.0531       \n\npdata &lt;- tibble(hp=seq_range(mt$hp,n=200)) %&gt;%\n  expand_grid(cyl=mt$cyl)\npdata$yhat &lt;- predict(model,newdata=pdata)\nggplot() +\n  geom_point(data=mt, aes(x=hp,y=mpg,color=cyl)) +\n  geom_line(data=pdata, aes(x=hp,y=yhat,color=cyl))"
  },
  {
    "objectID": "posts/modelling/index.html#nonlinear-regression",
    "href": "posts/modelling/index.html#nonlinear-regression",
    "title": "Modelling",
    "section": "Nonlinear Regression",
    "text": "Nonlinear Regression\nPackage minpack.lm uses Levenberg-Marquardt algorithm, which seems to be more forgiving compared with nls.\n\nlibrary(minpack.lm)\nmodel &lt;- nlsLM(conc ~ a * exp(-b*time), start=list(a=1,b=1), data=Indometh)\ntidy(model)\n\n# A tibble: 2 × 5\n  term  estimate std.error statistic  p.value\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 a         2.78    0.154       18.1 8.24e-27\n2 b         1.35    0.0994      13.6 1.58e-20\n\npdata &lt;- tibble(time=seq_range(Indometh$time,n=200))\npdata$yhat &lt;- predict(model,newdata=pdata)\nggplot() +\n  geom_point(data=Indometh, aes(x=time,y=conc)) +\n  geom_line(data=pdata, aes(x=time,y=yhat),color=\"red\")"
  },
  {
    "objectID": "posts/modelling/index.html#logistic-regression",
    "href": "posts/modelling/index.html#logistic-regression",
    "title": "Modelling",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\nmt &lt;- mtcars %&gt;% mutate(gas.guzzler=as.numeric(mpg&lt;22.5))\nmodel &lt;- glm(gas.guzzler ~ disp + am, data=mt,family=\"binomial\")\ntidy(model, exponentiate = TRUE)\n\n# A tibble: 3 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept) 0.00000705    6.01      -1.97   0.0483\n2 disp        1.09          0.0405     2.07   0.0389\n3 am          4.56          1.83       0.830  0.406 \n\npdata &lt;- crossing(disp=seq_range(mt$disp,n=200),\n                  am=mt$am)\npdata$yhat &lt;- predict(model,newdata=pdata,type=\"response\")\nggplot() + \n  geom_point(data=mt,aes(x=disp,y=gas.guzzler,color=factor(am))) +\n  geom_line(data=pdata, aes(x=disp,y=yhat,color=factor(am)))"
  },
  {
    "objectID": "posts/modelling/index.html#penalized-regression",
    "href": "posts/modelling/index.html#penalized-regression",
    "title": "Modelling",
    "section": "Penalized Regression",
    "text": "Penalized Regression\n\nRidge Regression\nUse ridge regression (a.k.a. L2 regularization) to fit a model in order to deal with multicollinearity and overfitting. A penalty factor \\(\\lambda\\) is used to minimize high coefficients. \\(\\lambda\\) = 0 is equivalent to ordinary least squares, and higher values means higher penalty. Using the glmnet package, set alpha = 0 for ridge regression.\nDetermine best \\(\\lambda\\) (produces lowest mean squared error) using k-fold cross-validation, cv.glmnet(). Note that predictors are standardized by default.\n\nlibrary(glmnet)\ny &lt;- mtcars$hp\nx &lt;- mtcars %&gt;% dplyr::select(mpg, wt, drat, qsec) %&gt;% as.matrix()\n\n#find optimal lambda value that minimizes test MSE\ncv_model &lt;- cv.glmnet(x, y, alpha = 0)\nbest_lambda &lt;- cv_model$lambda.min\n\nmodel &lt;- glmnet(x, y, alpha = 0, lambda = best_lambda)\ncoef(model)\n\n5 x 1 sparse Matrix of class \"dgCMatrix\"\n                     s0\n(Intercept) 477.1861699\nmpg          -3.2990043\nwt           20.0317433\ndrat         -0.4572541\nqsec        -18.3218541\n\n#calculate R-squared\ny_predicted &lt;- predict(model, s = best_lambda, newx = x)\nsst &lt;- sum((y - mean(y))^2)\nsse &lt;- sum((y_predicted - y)^2)\n#find R-Squared\nrsq &lt;- 1 - sse/sst\nrsq\n\n[1] 0.8018387\n\n\n\n\nLasso Regression\nLasso regression is similar but penalty is based on sum of absolute values coefficients. Setting alpha = 1 will perform Lasso (Elastic net is intermediate values for alpha). Note that Lasso can shrink coefficients down to zero.\n\ny &lt;- mtcars$hp\nx &lt;- mtcars %&gt;% select(mpg, wt, drat, qsec) %&gt;% as.matrix()\nmodel &lt;- glmnet(x, y, alpha = 1)\n\n#find optimal lambda value that minimizes test MSE\ncv_model &lt;- cv.glmnet(x, y, alpha = 1)\nbest_lambda &lt;- cv_model$lambda.min\n\nmodel &lt;- glmnet(x, y, alpha = 1, lambda = best_lambda)\ncoef(model)\n\n5 x 1 sparse Matrix of class \"dgCMatrix\"\n                    s0\n(Intercept) 482.031434\nmpg          -3.007899\nwt           20.645453\ndrat          .       \nqsec        -19.123746\n\n#calculate R-squared\ny_predicted &lt;- predict(model, s = best_lambda, newx = x)\nsst &lt;- sum((y - mean(y))^2)\nsse &lt;- sum((y_predicted - y)^2)\n#find R-Squared\nrsq &lt;- 1 - sse/sst\nrsq\n\n[1] 0.8026151"
  },
  {
    "objectID": "posts/modelling/index.html#mixed-effects",
    "href": "posts/modelling/index.html#mixed-effects",
    "title": "Modelling",
    "section": "Mixed Effects",
    "text": "Mixed Effects\n\nlibrary(lme4)\nlibrary(nlme)\n\nview.predict &lt;- function(fit) {\n  data1 %&gt;% mutate(pred_dist = fitted(fit)) %&gt;%\n    ggplot(aes(x=age, y=pred_dist, group=Subject, color=Subject)) + theme_classic() +\n    geom_line(size=1)\n}\n\ndata1 &lt;- Orthodont %&gt;% mutate(Subject=factor(Subject,ordered=FALSE))\ndata1 %&gt;%\n    ggplot(aes(x=age, y=distance, group=Subject, color=Subject, linetype=Sex)) +\n    geom_line(size=1) + theme_classic()\n\n\n\n# null model\nmod1 &lt;- lmer(distance ~ (1|Subject), data=data1, REML=F)\nsummary(mod1)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: distance ~ (1 | Subject)\n   Data: data1\n\n     AIC      BIC   logLik deviance df.resid \n   521.5    529.5   -257.7    515.5      105 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.2391 -0.5248 -0.1103  0.4827  2.7734 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Subject  (Intercept) 3.567    1.889   \n Residual             4.930    2.220   \nNumber of obs: 108, groups:  Subject, 27\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  24.0231     0.4216   56.98\n\nview.predict(mod1)\n\n\n\n# Random intercept model\nmod2 &lt;- lmer(distance ~ age + (1|Subject), data=data1, REML=F)\nsummary(mod2)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: distance ~ age + (1 | Subject)\n   Data: data1\n\n     AIC      BIC   logLik deviance df.resid \n   451.4    462.1   -221.7    443.4      104 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6870 -0.5386 -0.0123  0.4910  3.7470 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Subject  (Intercept) 4.294    2.072   \n Residual             2.024    1.423   \nNumber of obs: 108, groups:  Subject, 27\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 16.76111    0.79456   21.09\nage          0.66019    0.06122   10.78\n\nCorrelation of Fixed Effects:\n    (Intr)\nage -0.848\n\nview.predict(mod2)\n\n\n\n# Random intercept and random slope (independent)\nmod3 &lt;- lmer(distance ~ age + (1|Subject) + (0+age|Subject), data=data1, REML=F)\nsummary(mod3)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: distance ~ age + (1 | Subject) + (0 + age | Subject)\n   Data: data1\n\n     AIC      BIC   logLik deviance df.resid \n   449.7    463.1   -219.9    439.7      103 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7542 -0.5056  0.0181  0.5216  3.8017 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n Subject   (Intercept) 1.82570  1.3512  \n Subject.1 age         0.02141  0.1463  \n Residual              1.85944  1.3636  \nNumber of obs: 108, groups:  Subject, 27\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 16.76111    0.70816   23.67\nage          0.66019    0.06509   10.14\n\nCorrelation of Fixed Effects:\n    (Intr)\nage -0.822\n\nview.predict(mod3)\n\n\n\n# Random intercept and random slope (correlated)\nmod4 &lt;- lmer(distance ~ age + (1+age|Subject), data=data1, REML=F)\nsummary(mod4)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: distance ~ age + (1 + age | Subject)\n   Data: data1\n\n     AIC      BIC   logLik deviance df.resid \n   451.2    467.3   -219.6    439.2      102 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3060 -0.4874  0.0076  0.4822  3.9228 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n Subject  (Intercept) 4.81397  2.1941        \n          age         0.04619  0.2149   -0.58\n Residual             1.71623  1.3100        \nNumber of obs: 108, groups:  Subject, 27\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 16.76111    0.76076  22.032\nage          0.66019    0.06992   9.442\n\nCorrelation of Fixed Effects:\n    (Intr)\nage -0.848\n\nview.predict(mod4)"
  },
  {
    "objectID": "posts/polars/index.html",
    "href": "posts/polars/index.html",
    "title": "Polars notes",
    "section": "",
    "text": "Command reference for the polars Python package, with R equivalents.\n\nLoad package and data\n\n\n\nlibrary(tidyverse)\ndiamonds\nband_members\nband_instruments\n\n\n\n\n\nimport polars as pl\ndiamonds_polars = pl.from_pandas(r.diamonds)\nband_members_polars = pl.from_pandas(r.band_members)\nband_instruments_polars = pl.from_pandas(r.band_instruments)\n\n\n\n\nGenerate a data frame from scratch\n\n\n\ntibble(\n  id=1:3,\n  color=c(\"blue\",\"red\",\"green\"),\n  size=c(\"small\",\"medium\",\"large\")\n)\n\n\n\n\n\npl.DataFrame(\n  {\n    'id': [1, 2, 3],\n    'color': ['blue', 'red', 'green'],\n    'size': ['small', 'medium', 'large']\n  }\n).to_pandas()\n\n\n\n\n\nRead in a TSV file, explicitly\n\n\n\nfile &lt;- \"C:/Users/Ying/Desktop/samples/mock/Sample_GutZymo1_IGO_13699_36.kaiju_summary1.tsv\"\n\ncols &lt;- list(\n  \"outfile\"=col_character(), \n  \"percent\"=col_double(),\n  \"numseqs\"=col_integer(),\n  \"taxid\"=col_character(), \n  \"taxon_name\"=col_skip()\n)\ntable &lt;- read_tsv(file,skip=1,col_names=names(cols),col_types=cols, na=c(\"\", \"NA\"))\n\n\n\n\n\ncols = {\n  'outfile':pl.Utf8, \n  'percent':pl.Float64,\n  'numseqs':pl.Int64,\n  'taxid':pl.Utf8, \n  'taxon_name':None\n}\n\n# read_csv method: \ncolumns = [i for i,v in enumerate(cols.values()) if v is not None]\nnew_columns = [k for k,v in cols.items() if v is not None]\ndtypes = {k:v for k,v in cols.items() if v is not None}\ntable = pl.read_csv(r.file, skip_rows=1, sep='\\t', has_header=False, null_values=['','NA'], columns=columns, new_columns=new_columns, dtypes=dtypes)\n\n# lazy_csv method: \ncolnames = ['column_'+str(i+1) for i,v in enumerate(cols.values())]\ndtypes = {k:(v if v is not None else pl.Utf8) for k,v in zip(colnames,cols.values())}\nselect_expr = [pl.col(n).alias(c) for n,c,t in zip(colnames,cols.keys(),cols.values()) if t is not None]\ntable_lazy = pl.scan_csv(r.file, skip_rows=1, sep='\\t', has_header=False, dtypes=dtypes).select(select_expr).collect()\n\n\n\n\n\nExtract vector\n\n\n\ndiamonds$color #method 1\ndiamonds[[\"color\"]] #method 2\ndiamonds %&gt;% pull(color) #method 3\n\n\n\n\n\ndiamonds_polars['color'] #method 1\ndiamonds_polars.get_column('color') #method 2\n\n\n\n\n\n\nTable Characteristics\n\n\n\nnrow(diamonds) #height\nncol(diamonds) #width\ndim(diamonds) #height and width\nmap(diamonds,class) #list of classes\nglimpse(diamonds) #column datatypes\n\n\n\n\n\ndiamonds_polars.height #height\ndiamonds_polars.width #width\ndiamonds_polars.shape #height and width (tuple)\ndiamonds_polars.columns #column names (list)\ndiamonds_polars.dtypes #datatypes (list)\ndiamonds_polars.schema #column datatypes (dict)\n\n\n\n\n\nRow/Column Filtering\n\nExtract top 3 rows\n\n\n\ndiamonds[1:3,] #method 1\nhead(diamonds,3) #method 2\ndiamonds %&gt;% slice(1:3) #method 3\n\n\n\n\n\ndiamonds_polars[[1,2,3],:].to_pandas()\ndiamonds_polars.head(3).to_pandas()\n\n\n\n\n\nMultiple row filter criteria\n\n\n\ndiamonds %&gt;% \n  filter(clarity==\"VVS1\",\n         price&gt;2000,\n         grepl(\"[DEF]\",color))\n\n\n\n\n\n(diamonds_polars\n  .filter(\n    (pl.col('clarity')=='VVS1') &\n    (pl.col('price') &gt; 2000) & \n    (pl.col('color').cast(pl.Utf8).str.contains('[DEF]'))\n  )\n).to_pandas()\n\n\n\n\n\n\nSelect/Rename columns\n\nRoutine select\n\n\n\ndiamonds %&gt;% select(carat,cut,clarity)\n\n\n\n\n\n(diamonds_polars\n  .select(['carat','cut','clarity'])\n).to_pandas()\n\n\n\n\n\nSelect columns using regex pattern\n\n\n\ndiamonds %&gt;% select(matches(\"^c\"))\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.col('^c.*$')  \n  ])\n).to_pandas()\n\n\n\n\n\nSelect columns of a certain type\n\n\n\ndiamonds %&gt;% select(where(is.factor))\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.col(pl.Categorical)  \n  ])\n).to_pandas()\n\n\n\n\n\nSelect all columns except those specified\n\n\n\ndiamonds %&gt;% select(-c(x,y,z))\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.all().exclude(['x','y','z'])\n  ])\n).to_pandas()\n\n\n\n\n\nSelect columns and rename\n\n\n\ndiamonds %&gt;% select(price_usd=price,length=x,width=y,depth=z)\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.col('price').alias('price_usd'),\n    pl.col('x').alias('length'),\n    pl.col('y').alias('width'),\n    pl.col('z').alias('depth')\n  ])\n).to_pandas()\n\n\n\n\n\nSelect all columns and add prefix\n\n\n\ndiamonds %&gt;% rename_with(.fn=~paste0(\"var_\",.))\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.all().prefix('var_')\n  ])\n).to_pandas()\n\n\n\n\n\nSelect and programmatically rename\n\n\n\nvarmap &lt;- c(\"price_usd\"=\"price\",\n            \"length\"=\"x\",\n            \"width\"=\"y\",\n            \"depth\"=\"z\")\ndiamonds %&gt;% select(!!!varmap)\n\n\n\n\n\nvarmap = {'price':'price_usd',\n          'x':'length',\n          'y':'width',\n          'z':'depth'}\n(diamonds_polars\n  .select(varmap)\n  .rename(varmap)\n).to_pandas()\n\n\n\n\n\n\nMutate/Transmute\n\nMutate\n\n\n\ndiamonds %&gt;%\n  mutate(price_thousands=price*1000,\n         log_price=log(price),\n         xyz=paste(x,y,z,sep=\"+\"))\n\n\n\n\n\n(diamonds_polars\n  .with_columns([\n    (pl.col('price')*1000).alias('price_thousands'),\n    pl.col('price').log().alias('log_price'),\n    pl.concat_str([pl.col('x'),pl.col('y'),pl.col('z')],sep='+').alias('xyz')\n  ])\n).to_pandas()\n\n\n\n\n\nTransmute\n\n\n\ndiamonds %&gt;%\n  transmute(\n    color_is_DEF=color %in% c(\"D\",\"E\",\"F\"),\n    color_status=case_when(\n      color==\"J\" ~ \"very poor\",\n      color %in% c(\"H\",\"I\") ~ \"poor\",\n      color %in% c(\"F\",\"G\") ~ \"ok\",\n      TRUE ~ \"excellent\"\n    ),\n    clarity=str_to_title(clarity))\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.col('color').cast(pl.Utf8).is_in(['D','E','F']).alias('color_is_DEF'),\n    pl.when(pl.col('color')=='J').then('very poor')\n      .when(pl.col('color').cast(pl.Utf8).is_in(['H','I'])).then('poor')\n      .when(pl.col('color').cast(pl.Utf8).is_in(['F','G'])).then('ok')\n      .otherwise('excellent')\n      .alias('color_status'),\n    pl.col('clarity').apply(lambda s: s.title())\n  ])\n).to_pandas()\n\n\n\n\n\n\nGroup By and Summarize\n\nCount rows by group\n\n\n\ndiamonds %&gt;% \n  group_by(cut,color) %&gt;%\n  summarize(n=n(),\n            .groups=\"drop\")\n\ndiamonds %&gt;% count(cut,color) #shortcut\n\n\n\n\n\n(diamonds_polars\n  .groupby(['cut','color'])\n  .agg([\n    pl.count().alias('n')\n  ])\n).to_pandas()\n\n\n\n\n\nCalculate various summaries by group\n\n\n\ndiamonds %&gt;%\n  group_by(cut) %&gt;%\n  summarize(n=n(),\n            mean_price=mean(price),\n            max_price=max(price),\n            available_colors=paste(sort(unique(color)),collapse=\", \"),\n            .groups=\"drop\")\n\n\n\n\n\n(diamonds_polars\n  .groupby('cut')\n  .agg([\n    pl.count().alias('n'),\n    pl.col('price').mean().alias('mean_price'),\n    pl.col('price').max().alias('max_price'),\n    pl.col('color').unique().cast(pl.Utf8).sort().str.concat(', ').alias('availble_colors')\n  ])\n).to_pandas()\n\n\n\n\n\nSelect first row after sorting, by group\n\n\n\ndiamonds %&gt;%\n  group_by(cut) %&gt;%\n  arrange(desc(price),depth) %&gt;%\n  slice(1) %&gt;%\n  ungroup()\n\n\n\n\n\n(diamonds_polars\n  .sort(['price','depth'],reverse=[True,False])\n  .groupby('cut')\n  .head(1)\n).to_pandas()\n\n\n\n\n\n\nApply function across columns\n\nApply to all columns\n\n\n\ndiamonds %&gt;% \n  mutate(across(.fns=~paste0(.,\"_xyz\")))\n\n\n\n\n\n(diamonds_polars\n  .with_columns([\n    pl.all()+'_xyz'\n  ])\n).to_pandas()\n\n\n\n\n\nApply to columns using regex\n\n\n\ndiamonds %&gt;% \n  transmute(across(.cols=matches(\"^c\"),.fns=~paste0(.,\"_x\")))\n\n\n\n\n\n(diamonds_polars\n  .select([\n    pl.col('^c.*$') + '_x'\n  ])\n).to_pandas()\n\n\n\n\n\nApply to columns of a certain type\n\n\n\ndiamonds %&gt;% \n  mutate(across(.cols=where(is.numeric),\n                .fns=~. * 1000))\n\n\n\n\n\n(diamonds_polars\n  .with_columns([\n    pl.col([pl.Float64,pl.Int32]) * 1000\n  ])\n).to_pandas()\n\n\n\n\n\n\nJoins\n\nLeft join\n\n\n\nband_members %&gt;% left_join(band_instruments,by=\"name\")\n\n\n\n\n\n(band_members_polars\n  .join(band_instruments_polars,on='name',how='left')\n).to_pandas()\n\n\n\n\n\nInner join\n\n\n\nband_members %&gt;% inner_join(band_instruments,by=\"name\")\n\n\n\n\n\n(band_members_polars\n  .join(band_instruments_polars,on='name',how='inner')\n).to_pandas()\n\n\n\n\n\nOuter join\n\n\n\nband_members %&gt;% full_join(band_instruments,by=\"name\")\n\n\n\n\n\n(band_members_polars\n  .join(band_instruments_polars,on='name',how='outer')\n).to_pandas()\n\n\n\n\n\nAnti join\n\n\n\nband_members %&gt;% anti_join(band_instruments,by=\"name\")\n\n\n\n\n\n(band_members_polars\n  .join(band_instruments_polars,on='name',how='anti')\n).to_pandas()\n\n\n\n\n\n\nPivoting/Reshaping\n\nPivot Longer\n\n\n\ndiamonds %&gt;%\n  pivot_longer(cols=c(x,y,z),names_to=\"axis\",values_to=\"mm\")\n\n\n\n\n\n(diamonds_polars\n  .melt(id_vars=list(set(diamonds_polars.columns).difference(['x','y','z'])),variable_name='variable',value_name='value')\n).to_pandas()\n\n\n\n\n\nPivot Wider\n\n\n\ndiamonds %&gt;%\n  pivot_wider(id_cols=clarity,names_from=cut,values_from=price,values_fn=mean)\n\n\n\n\n\n(diamonds_polars\n  .pivot(index='clarity',values='price',columns='cut',aggregate_fn='mean')\n).to_pandas()\n\n\n\n\n\n\nNested columns\n\nSplit string column into nested list, unnest into long format\n\n\n\ndiamonds %&gt;%\n  mutate(cut_word=str_split(cut,\" \")) %&gt;%\n  unnest(cut_word)\n\n\n\n\n\n(diamonds_polars\n  .with_columns([\n    pl.col('cut').cast(pl.Utf8).str.split(' ').alias('cut_word'),\n  ])\n  .explode('cut_word')\n).to_pandas()\n\n\n\n\n\nGroup by a variable and tally others in a nested field\n\n\n\ndiamonds %&gt;% \n  group_by(cut) %&gt;%\n  summarize(clarity_table=list(table(clarity)),\n            .groups=\"drop\")\n\n\n\n\n\n(diamonds_polars\n  .groupby('cut')\n  .agg([\n    pl.col('clarity').value_counts().alias('clarity_counts')\n  ])\n).to_pandas()\n\n\n\n\n\nMove columns into single nested column, then unnest to individual columns again.\n\n\n\ndiamonds %&gt;%\n  nest(col_color_clarity=c(cut,color,clarity)) %&gt;%\n  unnest(col_color_clarity)\n\n\n\n\n\n(diamonds_polars\n  .with_columns([\n    pl.struct(pl.col(['cut','color','clarity'])).alias('cut_color_clarity')\n  ])\n  .drop(['cut','color','clarity'])\n  .unnest('cut_color_clarity')\n).to_pandas()\n\n\n\n\n\nNested table in a single column, by group\n\n\n\ndiamonds %&gt;%\n  group_by(color) %&gt;%\n  nest(group_info=-color) %&gt;%\n  ungroup()\n\n\n\n\n\n(diamonds_polars\n  .groupby('color')\n  .agg([\n    pl.struct(pl.all().exclude('color')).alias('group_info')\n  ])\n).to_pandas()\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;       \n\n\n\n\n\n\n\n\n\n–&gt;       \n\n\n\n\n\n\n\n\n\n–&gt;       \n\n\n\n\n\n\n\n\n\n–&gt;"
  },
  {
    "objectID": "posts/quarto/index.html",
    "href": "posts/quarto/index.html",
    "title": "Quarto Cheatsheet",
    "section": "",
    "text": "italics bold asdf some blue text\nverbatim code inline math: \\(E = mc^{2}\\) https://quarto.org link to Quarto\nBullet List\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\n\nNumberbed list (4-space indent seems preferable)\n\nasdf\nasdf2\n\nasdf\nsdf\n\nasdf 3\n\n\n\n\n\n\n\nNote\n\n\n\nCallouts: note that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\n\n\n\nHere is a footnote reference,1 and another.2 You can also reference inline!3\n\nThe whole paragraph can be indented, or just the first line. In this way, multi-paragraph footnotes work like multi-paragraph list items."
  },
  {
    "objectID": "posts/quarto/index.html#markdown-basics",
    "href": "posts/quarto/index.html#markdown-basics",
    "title": "Quarto Cheatsheet",
    "section": "",
    "text": "italics bold asdf some blue text\nverbatim code inline math: \\(E = mc^{2}\\) https://quarto.org link to Quarto\nBullet List\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\nunordered list\n\nsub-item 1\nsub-item 2\n\nsub-sub-item 1\n\n\n\nNumberbed list (4-space indent seems preferable)\n\nasdf\nasdf2\n\nasdf\nsdf\n\nasdf 3\n\n\n\n\n\n\n\nNote\n\n\n\nCallouts: note that there are five types of callouts, including: note, tip, warning, caution, and important.\n\n\n\n\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\n\n\n\nHere is a footnote reference,1 and another.2 You can also reference inline!3\n\nThe whole paragraph can be indented, or just the first line. In this way, multi-paragraph footnotes work like multi-paragraph list items."
  },
  {
    "objectID": "posts/quarto/index.html#running-r-code",
    "href": "posts/quarto/index.html#running-r-code",
    "title": "Quarto Cheatsheet",
    "section": "Running R Code",
    "text": "Running R Code\n\nCode with output:\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\nd &lt;- diamonds\nhead(d)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\n\n\nLoad R packages silently (nothing shown below):\n\n\n\nUn-evaluated code:\n\nsqrt(-2)\n\n\n\nFolded code, with tidy-ing of code:\n\n\nCode\nr_fibonacci &lt;- function(n) {\n    if (n &lt;= 1) {\n        return(n)\n    } else {\n        return(r_fibonacci(n - 1) + r_fibonacci(n - 2))\n    }\n}\nr_fibonacci(10)\n\n\n[1] 55\n\n\n\n\nPlot with options:\n\nggplot(d, aes(x = carat, y = price, color = cut)) + geom_point()\n\n\n\n\nDiamond plot"
  },
  {
    "objectID": "posts/quarto/index.html#running-python",
    "href": "posts/quarto/index.html#running-python",
    "title": "Quarto Cheatsheet",
    "section": "Running Python",
    "text": "Running Python\n\nPython code\n\nimport os,sys,time\ndef py_fibonacci(n):\n  if n &lt;= 1:\n    return n\n  else:\n    return(py_fibonacci(n-1) + py_fibonacci(n-2))\npy_fibonacci(10)\n\n55\n\n\n\n\nGoing back and forth between R and Python:\nR:\n\ndata &lt;- mtcars %&gt;%\n    select(mpg, cyl, disp)\nhead(data, 3)\n\n               mpg cyl disp\nMazda RX4     21.0   6  160\nMazda RX4 Wag 21.0   6  160\nDatsun 710    22.8   4  108\n\n\nPython:\n\nr.data = r.data.assign(km_per_liter=lambda x: x.mpg / 2.352)\nr.data.head(3)\n\n                mpg  cyl   disp  km_per_liter\nMazda RX4      21.0  6.0  160.0      8.928571\nMazda RX4 Wag  21.0  6.0  160.0      8.928571\nDatsun 710     22.8  4.0  108.0      9.693878\n\n\nBack to R:\n\ndata &lt;- data %&gt;% mutate(mpg_converted = km_per_liter * 2.352)\nhead(data,3)\n\n               mpg cyl disp km_per_liter mpg_converted\nMazda RX4     21.0   6  160     8.928571          21.0\nMazda RX4 Wag 21.0   6  160     8.928571          21.0\nDatsun 710    22.8   4  108     9.693878          22.8\n\n\n\n\nR code inline:\nThe column names in data are: mpg, cyl, disp, km_per_liter, mpg_converted"
  },
  {
    "objectID": "posts/quarto/index.html#tables",
    "href": "posts/quarto/index.html#tables",
    "title": "Quarto Cheatsheet",
    "section": "Tables",
    "text": "Tables\n\nSimple markdown table:\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\n\n\nKable output\n\nknitr::kable(head(mtcars,3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\n\n\n\n\n\nDatatable output\n\nDT::datatable(head(mtcars,3))\n\n\n\n\n\n\n\ng &lt;- ggplot(mtcars,aes(x=mpg,y=disp)) +  geom_point()\ng\n\n\n\n\n\n\nCode blocks and output"
  },
  {
    "objectID": "posts/quarto/index.html#layouts",
    "href": "posts/quarto/index.html#layouts",
    "title": "Quarto Cheatsheet",
    "section": "Layouts",
    "text": "Layouts\n\nTwo outputs, side-by-side (simple)\n\nlibrary(knitr)\n\nWarning: package 'knitr' was built under R version 4.2.2\n\n# table on the left\nkable(head(mtcars[, 1:3]))\n# table on the right\nkable(head(cars,3))\n\n\nTwo tables\n\n\n\n\nmtcars\n\n\n\nmpg\ncyl\ndisp\n\n\n\n\nMazda RX4\n21.0\n6\n160\n\n\nMazda RX4 Wag\n21.0\n6\n160\n\n\nDatsun 710\n22.8\n4\n108\n\n\nHornet 4 Drive\n21.4\n6\n258\n\n\nHornet Sportabout\n18.7\n8\n360\n\n\nValiant\n18.1\n6\n225\n\n\n\n\n\n\nJust cars\n\n\nspeed\ndist\n\n\n\n\n4\n2\n\n\n4\n10\n\n\n7\n4\n\n\n\n\n\n\n\n\n\nmargin plot:\n\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\n\n\n\n\n\nFigure 1: MPG vs horsepower, colored by transmission.\n\n\n\n\n\nAside:\nQuarto uses the concept of columns to describe page layout (e.g. the “body” column, the “margin” column, etc.). Here is some text.  Below we’ll describe how to arrange content into these columns.This is a span that has the class aside which places it in the margin without a footnote number.\nAll of the layout capabilities described in this document work for HTML output and many work for PDF and LaTeX output. For details about the PDF / LaTeX output, see PDF/LaTeX Layout.\n\n\nColumn margin\n\nhead(mtcars)\n\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]\n\n\nTabset:\n\nCodeOutput\n\n\n\nhead(mtcars)\n\n\n\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n\n\n\n\n\nFigure layout with fenced divs:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure layout\n\n\n\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "posts/quarto/index.html#footnotes",
    "href": "posts/quarto/index.html#footnotes",
    "title": "Quarto Cheatsheet",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere is the footnote.↩︎\nHere’s one with multiple blocks. Subsequent paragraphs are indented to show that they belong to the previous footnote.\n{ some.code }\n↩︎\nHello. I am an inline footnote.↩︎"
  },
  {
    "objectID": "posts/R_install/index.html",
    "href": "posts/R_install/index.html",
    "title": "R install notes",
    "section": "",
    "text": "Install:\n\nR\nRtools\nRStudio\nGit for Windows\nJava JDK 32/64 bit.\n\n\n\n\nInstall:\n\nR (r-base, r-base-dev)\nRstudio\ndefault-jre, default-jdk, libcurl4-openssl-dev, git, cmake\n\n\n# update indices\nsudo apt update -qq\n# install two helper packages we need\nsudo apt install --no-install-recommends software-properties-common dirmngr\n# add the signing key (by Michael Rutter) for these repos\n# To verify key, run gpg --show-keys /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc \n# Fingerprint: E298A3A825C0D65DFD57CBB651716619E084DAB9\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\n# add the R 4.0 repo from CRAN -- adjust 'focal' to 'groovy' or 'bionic' as needed\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n\nsudo apt install --no-install-recommends r-base r-base-dev\n\nsudo apt install default-jre default-jdk libcurl4-openssl-dev git cmake\n\n\n\n\nInstall: * R * RStudio * JDK (x64)"
  },
  {
    "objectID": "posts/R_install/index.html#r-installation",
    "href": "posts/R_install/index.html#r-installation",
    "title": "R install notes",
    "section": "",
    "text": "Install:\n\nR\nRtools\nRStudio\nGit for Windows\nJava JDK 32/64 bit.\n\n\n\n\nInstall:\n\nR (r-base, r-base-dev)\nRstudio\ndefault-jre, default-jdk, libcurl4-openssl-dev, git, cmake\n\n\n# update indices\nsudo apt update -qq\n# install two helper packages we need\nsudo apt install --no-install-recommends software-properties-common dirmngr\n# add the signing key (by Michael Rutter) for these repos\n# To verify key, run gpg --show-keys /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc \n# Fingerprint: E298A3A825C0D65DFD57CBB651716619E084DAB9\nwget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc\n# add the R 4.0 repo from CRAN -- adjust 'focal' to 'groovy' or 'bionic' as needed\nsudo add-apt-repository \"deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/\"\n\nsudo apt install --no-install-recommends r-base r-base-dev\n\nsudo apt install default-jre default-jdk libcurl4-openssl-dev git cmake\n\n\n\n\nInstall: * R * RStudio * JDK (x64)"
  },
  {
    "objectID": "posts/R_install/index.html#r-packages",
    "href": "posts/R_install/index.html#r-packages",
    "title": "R install notes",
    "section": "R packages",
    "text": "R packages\n\ncran.pkgs &lt;- c(\n  \"tidyverse\",   # essential suite of R tools\n  \"rlang\",       # tools for programming (e.g. tidy eval)\n  \"roxygen2\",    # documentation system for R packages\n  \"remotes\",     # installing from Github\n  \"reticulate\",  # Python interface\n  \"BiocManager\", # installer for Bioconductor\n  \"DT\",          # datatables\n  \"shiny\",       # interactivity in R\n  \"usethis\",     # package development\n)\ninstall.packages(cran.pkgs)\n\noptional.pkgs &lt;- c(\n  \"rbenchmark\", \n  \"tictoc\",\n  \"cmprsk\",\n  \"Hmisc\",\n  \"formula.tools\",\n  \"reshape2\",\n  \"logistf\",\n  \"pingr\",\n  \"styler\",\n  \"coxphf\",\n  \"Rtsne\",\n  \"umap\",\n  \"rjson\",\n  \"plyr\",\n  \"xlsx\",\n  \"ggrepel\",\n  \"ggfittext\",\n  \"shinycssloaders\",\n  \"shinyvalidate\",\n  \"ggiraph\",\n  \"RJDBC\",\n  \"patchwork\"\n)\ninstall.packages(optional.pkgs)\n\nbioc.pkgs &lt;- c(\n  \"dada2\",\n  \"seqinr\",\n  \"phyloseq\",\n  \"ggtree\",\n  \"msa\",\n  \"phytools\",\n  \"DECIPHER\",\n  \"phangorn\"\n)\nBiocManager::install(bioc.pkgs)\n\n\n\nremotes::install_github(\"ying14/yingtools2\")\nremotes::install_github(\"csgillespie/roxygen2Comment\")\n\n# remotes::install_git(\"https://github.mskcc.org/taury/ytrecipes.git\")\n# remotes::install_git(\"https://github.mskcc.org/taury/ytdata.git\")\n# remotes::install_git(\"https://github.mskcc.org/taury/ytpipeline.git\")\n\n\n\n# git clone https://github.com/ying14/yingtools2\n# git clone https://github.mskcc.org/taury/ytrecipes\n# git clone https://github.mskcc.org/taury/ytdata\n# git clone https://github.mskcc.org/taury/ytpipeline"
  },
  {
    "objectID": "posts/R_install/index.html#install-miniconda-for-r",
    "href": "posts/R_install/index.html#install-miniconda-for-r",
    "title": "R install notes",
    "section": "Install Miniconda for R",
    "text": "Install Miniconda for R\n\nreticulate::py_config()\n\npython:         C:/Users/Ying/AppData/Local/r-miniconda/envs/r-reticulate/python.exe\nlibpython:      C:/Users/Ying/AppData/Local/r-miniconda/envs/r-reticulate/python38.dll\npythonhome:     C:/Users/Ying/AppData/Local/r-miniconda/envs/r-reticulate\nversion:        3.8.15 (default, Nov 21 2022, 10:47:13) [MSC v.1916 64 bit (AMD64)]\nArchitecture:   64bit\nnumpy:          C:/Users/Ying/AppData/Local/r-miniconda/envs/r-reticulate/Lib/site-packages/numpy\nnumpy_version:  1.23.2"
  },
  {
    "objectID": "posts/R_install/index.html#r-startup",
    "href": "posts/R_install/index.html#r-startup",
    "title": "R install notes",
    "section": "R startup:",
    "text": "R startup:\nR environment (site):\n\nFile specified by R_ENVIRON\nR_HOME/etc/Renviron.site\n\nR environment (user):\n\nFile specified by R_ENVIRON_USER\n&lt;current_dir&gt;/.Renviron\n&lt;user_home_dir&gt;/.Renviron\n\nR profile (site):\n\nFile specified by R_PROFILE\nR_HOME/etc/Rprofile.site\n\nR profile (user):\n\nFile specified by R_PROFILE_USER\n&lt;current_dir&gt;/.Rprofile\n&lt;user_home_dir&gt;/.Rprofile\n\n.libPaths() determined by: R_LIBS_USER"
  },
  {
    "objectID": "posts/sql_commands/index.html",
    "href": "posts/sql_commands/index.html",
    "title": "SQL Commands",
    "section": "",
    "text": "Create a SQL object in R\n\nlibrary(tidyverse)\nlibrary(dbplyr)\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \":memory:\")\ncopy_to(con, diamonds)\ndiamonds2 &lt;- tbl(con, \"diamonds\")\ndiamonds2\n\n# Source:   table&lt;diamonds&gt; [?? x 10]\n# Database: sqlite 3.39.4 [:memory:]\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# … with more rows\n\n\n\nFilter by column criteria\n\n\n\ndiamonds %&gt;% \n  filter(clarity==\"VVS1\",\n         price&gt;2000,\n         grepl(\"good\",cut,ignore.case=TRUE))\n\n\n\n\n\nSELECT *\nFROM diamonds\nWHERE\n  clarity = 'VVS1' AND\n  price &gt; 2000 AND\n  LOWER(cut) like '%good%'\n\n\n\n\n\nSummarize by group\n\n\n\ndiamonds %&gt;%\n  group_by(cut,color) %&gt;% \n  summarize(n=n(),\n            min_price=min(price),\n            max_price=max(price),\n            mean_price=mean(price),\n            n_distinct_price=n_distinct(price),\n            .groups=\"drop\") \n\n\n\n\n\nSELECT\n  cut,\n  color,\n  COUNT(*) AS n,\n  MIN(price) AS min_price,\n  MAX(price) AS max_price,\n  AVG(price) AS mean_price,\n  COUNT(DISTINCT price) AS n_distinct_price\nFROM diamonds\nGROUP BY cut, color\n\n\n\n\n\ncalculations by window\n\n\n\ndiamonds %&gt;%\n  select(cut,price) %&gt;% \n  mutate(rownumber=row_number(),\n         price_rank=row_number(price),\n         total_rows=n()) %&gt;%\n  group_by(cut) %&gt;%\n  mutate(total_rows_in_group=n(),\n         rownumber_in_group=row_number(),\n         price_rank_in_group=row_number(price)) %&gt;%\n  ungroup()\n\n\n\n\n\nSELECT\n  cut,\n  price,\n  ROW_NUMBER() OVER () AS rownumber,\n  ROW_NUMBER() OVER (ORDER BY price) AS price_rank,\n  COUNT(*) OVER () AS total_rows,\n  ROW_NUMBER() OVER (PARTITION BY cut) AS rownumber_in_group,\n  ROW_NUMBER() OVER (PARTITION BY cut ORDER BY price) AS price_rank_in_group,\n  COUNT(*) OVER (PARTITION BY cut) AS total_rows_in_group\nFROM diamonds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;        \nCheck if B is a subset of A:\nSELECT * \nFROM B\nWHERE NOT EXISTS (SELECT 1 \n                   FROM   A \n                   WHERE  A.ID = B.ID)\nwith\nw (mrn, ord_id, test_date) as\n( select distinct LR_MRN, LR_ORD_ID, LR_PERFORMED_DTE from\nidb.LAB_TEXT_LINE\nJOIN idb.LAB_RESULTS\non LR_MRN=LTL_MRN\nand LR_PERFORMED_DTE=LTL_PERFORMED_DTE\nand LR_RESULT_GUID=LTL_RESULT_GUID\n\nx (key, val, rnum) AS\n( SELECT LTL_RESULT_GUID, LTL_TEXT_RESULT, LTL_LINE_NO\nFROM idb.LAB_TEXT_LINE\nJOIN idb.LAB_RESULTS\non LR_MRN=LTL_MRN\nand LR_PERFORMED_DTE=LTL_PERFORMED_DTE\nand LR_RESULT_GUID=LTL_RESULT_GUID\njoin w\non LR_MRN=mrn\nand LR_ORD_ID=ord_id\nand LR_PERFORMED_DTE=test_date),\n\ny(key, str, cnt, cnt_max) AS\n( SELECT key, VARCHAR('', 14025), 0, MAX(rnum)\nFROM x\nGROUP BY key\nUNION ALL\nSELECT y.key, y.str || RTRIM(CHAR(x.val)), y.cnt + 1, y.cnt_max\nFROM x, y\nWHERE x.key = y.key AND\nx.rnum = y.cnt + 1 AND\ny.cnt &lt; y.cnt_max ),\n\nz as (SELECT key, str\nFROM y\nWHERE y.cnt = y.cnt_max)\n\nselect * from idb.LAB_RESULTS left join z\non LR_RESULT_GUID=KEY"
  },
  {
    "objectID": "posts/web_scraping/index.html",
    "href": "posts/web_scraping/index.html",
    "title": "Webscraping in R",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(yingtools2)\nrm(list=ls())\nurls &lt;- c(\"https://www.societyforscience.org/regeneron-sts/2020-scholars/\",\n         \"https://www.societyforscience.org/regeneron-sts/2021-scholars/\",\n         \"https://www.societyforscience.org/regeneron-sts/2023-scholars/\")\n\nget.scholars &lt;- function(url) {\n  html &lt;- read_html(url)\n  lines &lt;- html %&gt;% html_elements(\"p\") %&gt;% html_text()\n  lines &lt;- lines[str_detect(lines,\"Age:\")]\n  tbl &lt;- tibble(lines=lines) %&gt;%\n    extract(lines,into=c(\"student\",\"age\",\"high.school\",\"title\"),regex=\"([\\\\S\\\\s]+), Age: ([0-9]+\\\\n?)([\\\\S\\\\s]+)\\nProject Title: ([\\\\S\\\\s]+)\",remove=FALSE)\n  tbl\n}\n\nscholars &lt;- urls %&gt;% setNames(.,.) %&gt;% \n  map_dfr(get.scholars,.id=\"url\") %&gt;%\n  mutate(state=str_extract(high.school,\"[A-Z]{2}\"))\n\nscholars %&gt;% count(state,sort=T) %&gt;% head(10) %&gt;% knitr::kable()\n\n\n\n\nstate\nn\n\n\n\n\nNY\n274\n\n\nCA\n117\n\n\nNJ\n56\n\n\nMA\n48\n\n\nVA\n36\n\n\nFL\n34\n\n\nTX\n33\n\n\nNC\n32\n\n\nCT\n29\n\n\nMD\n28\n\n\n\n\nscholars %&gt;% count(high.school,sort=T) %&gt;% head(10) %&gt;% knitr::kable()\n\n\n\n\nhigh.school\nn\n\n\n\n\nBronx High School of Science, NY\n20\n\n\nNorth Carolina School of Science and Mathematics, NC\n20\n\n\nBergen County Academies, NJ\n18\n\n\nOssining High School, NY\n13\n\n\nBergen County Academies, Hackensack, NJ\n11\n\n\nBronx High School of Science, Bronx, NY\n11\n\n\nByram Hills High School, NY\n11\n\n\nSyosset High School, NY\n11\n\n\nThe Harker School, CA\n10\n\n\nGreenwich High School, CT\n9"
  },
  {
    "objectID": "posts/web_scraping/index.html#section",
    "href": "posts/web_scraping/index.html#section",
    "title": "Webscraping in R",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rvest)\nlibrary(yingtools2)\nrm(list=ls())\nurls &lt;- c(\"https://www.societyforscience.org/regeneron-sts/2020-scholars/\",\n         \"https://www.societyforscience.org/regeneron-sts/2021-scholars/\",\n         \"https://www.societyforscience.org/regeneron-sts/2023-scholars/\")\n\nget.scholars &lt;- function(url) {\n  html &lt;- read_html(url)\n  lines &lt;- html %&gt;% html_elements(\"p\") %&gt;% html_text()\n  lines &lt;- lines[str_detect(lines,\"Age:\")]\n  tbl &lt;- tibble(lines=lines) %&gt;%\n    extract(lines,into=c(\"student\",\"age\",\"high.school\",\"title\"),regex=\"([\\\\S\\\\s]+), Age: ([0-9]+\\\\n?)([\\\\S\\\\s]+)\\nProject Title: ([\\\\S\\\\s]+)\",remove=FALSE)\n  tbl\n}\n\nscholars &lt;- urls %&gt;% setNames(.,.) %&gt;% \n  map_dfr(get.scholars,.id=\"url\") %&gt;%\n  mutate(state=str_extract(high.school,\"[A-Z]{2}\"))\n\nscholars %&gt;% count(state,sort=T) %&gt;% head(10) %&gt;% knitr::kable()\n\n\n\n\nstate\nn\n\n\n\n\nNY\n274\n\n\nCA\n117\n\n\nNJ\n56\n\n\nMA\n48\n\n\nVA\n36\n\n\nFL\n34\n\n\nTX\n33\n\n\nNC\n32\n\n\nCT\n29\n\n\nMD\n28\n\n\n\n\nscholars %&gt;% count(high.school,sort=T) %&gt;% head(10) %&gt;% knitr::kable()\n\n\n\n\nhigh.school\nn\n\n\n\n\nBronx High School of Science, NY\n20\n\n\nNorth Carolina School of Science and Mathematics, NC\n20\n\n\nBergen County Academies, NJ\n18\n\n\nOssining High School, NY\n13\n\n\nBergen County Academies, Hackensack, NJ\n11\n\n\nBronx High School of Science, Bronx, NY\n11\n\n\nByram Hills High School, NY\n11\n\n\nSyosset High School, NY\n11\n\n\nThe Harker School, CA\n10\n\n\nGreenwich High School, CT\n9"
  },
  {
    "objectID": "posts/wsl_notes/index.html",
    "href": "posts/wsl_notes/index.html",
    "title": "WSL2 Notes",
    "section": "",
    "text": "wsl-vpnkit\nNeed this to get VPN to work in WSL2 session. link: https://github.com/sakai135/wsl-vpnkit\nStart VPN service:\nwsl.exe -d wsl-vpnkit service wsl-vpnkit start\nStart VPN service only if needed\nwsl.exe -d wsl-vpnkit service wsl-vpnkit status &gt;/dev/null ||   wsl.exe -d wsl-vpnkit service wsl-vpnkit start\nStop service\nwsl.exe -d wsl-vpnkit service wsl-vpnkit stop\nsudo apt install python3-pip"
  }
]